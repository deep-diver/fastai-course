---
title: '2장: 이미지 분류 문제 다루기'
description:
  '이미지 분류 문제를 다루는 다양한 방식을 계층적 API로 살펴봅니다.'
prev: /chapter1
next: null
type: chapter
id: 2
---

<exercise id="1" title="함수로 레이블 추출하여 입력 데이터를 준비하기">

fastai는 이미지 분류 모델을 만드는 가장 간단한 방법으로 `ImageDataLoaders` 객체와 `cnn_learner` 함수를 제공합니다. 머신러닝으로 문제를 해결하려면 **1. 데이터** 와 **2. 모델 및 모델을 학습시키는 기법** 이 필요하며, 이 둘이 각각에 대응되는 역할을 합니다.

좀 더 구체적으로는 머신러닝 모델이 데이터를 소비하기 위해서는, 데이터가 모델이 이해할 수 있는 형식으로 포장된 다음 모델로 전달되어야 합니다. [`ImageDataLoaders`](https://docs.fast.ai/vision.data.html#ImageDataLoaders) 클래스가 제공하는 여러 (팩터리)메서드가 바로 이 역할을 수행하죠. 아래 코드의 [`from_name_func`](https://docs.fast.ai/vision.data.html#ImageDataLoaders.from_name_func)는 그 중 한 메서드입니다. 

우선 `ImageDataLoaders`의 `from_name_func` 메서드를 이해해보죠. 메서드의 이름은 `from name func` 세 부분으로 나눠서 지어졌습니다. 모델에 입력될 데이터를 가져온다(**from**). 파일 이름(**name**)으로부터 가져온다. 레이블 추출 방식에는 함수(**func**)를 사용한다. 라는 의미를 가지죠. 이 의미를 생각한 채 입력되는 처음 세 파라미터를 파악해보죠.
- **첫 번째 파라미터**: 모델에 입력될 파일(데이터)을 검색할 디렉터리를 지정합니다.
- **두 번째 파라미터**: 모델에 입력될 파일 이름 목록을 지정합니다. 첫 번째 파라미터의 경로로부터 검색합니다. 만약 파일 이름에 디렉터리가 포함되어 있다면, 파일 이름을 제외하고는 무시됩니다.
- **세 번째 파라미터**: 레이블을 추출하는 함수를 지정합니다. 이 함수는 개별 파일 이름을 입력 받아, 해당 파일의 레이블을 만들어서 반환해야 합니다. 

이 점을 유의해서 아래 코드를 읽고, `from_name_func` 메서드의 첫 번째와 두 번째 파라미터를 채워넣어 보세요. 그리고 이어지는 선택형 문제를 풀어보기 바랍니다. 참고로 아래 코드에서 사용된 데이터셋에는 **강아지**와 **고양이** 이미지가 포함되어 있는데, **강아지** 이미지 파일명은 _소문자_로, **고양이** 이미지 파일명은 _대문자_로 시작하는 특징이 있습니다(즉 강아지, 고양이를 구분하는 문제에 맞춰진 형태로 데이터 입력을 구성합니다).

<codeblock id="02_01">
첫 번째와 두 번째 파라미터의 역할이 무엇인지 생각해 보세요!
</codeblock>

상기 코드에서 `from_name_func`의 **세 번째 파라미터**는 무엇을 의미할까요?

<choice>
<opt text="파일이름의 첫 번째 문자를 대문자로 변환하여 반환"></opt>
<opt text="파일이름의 첫 번째 문자가 대문자면 True, 그렇지 않으면 False를 반환" correct="true"></opt>
<opt text="파일이름 전체가 대문자면 True, 그렇지 않으면 False를 반환"></opt>
<opt text="파일이름의 첫 번째 문자가 대문자면 False, 그렇지 않으면 True를 반환"></opt>
</choice>

</exercise>

<exercise id="2" title="정규 표현식으로 레이블 추출하여 입력 데이터를 준비하기">

이전 내용에서는 고양이와 강아지를 구분하는 문제를 위한 데이터 입력 구성 방식을 알아보았습니다. 이번에는 고양이, 강아지 대신 동물들의 **품종**을 구분하는 문제를 다룬다고 가정해보죠. 

앞서 사용한 데이터셋의 각 이미지 파일명 자체에 **품종** 정보가 함께 포함되어 있습니다. 따라서 다른 데이터셋을 사용할 필요가 없습니다. 대신 파일명에서 **품종**을 표현하는 특정 부분만을 추출할 방법이 필요합니다. 앞서 사용한 `from_name_func` (팩터리)메서드로도 가능할테죠. 

아래의 코드 중 `label_func` 함수를 완성해 보세요. 이 함수는 주어진 파일명으로부터 레이블 문자열만을 추출해 반환하는 기능을 합니다. 가령 아래 코드의 `filename1`의 값은 `Bombay_167.jpg`인데, 여기서 레이블은 `Bombay`가 되죠. 또 `filename2`의 값은 `american_bulldog_26.jpg`인데, 여기서의 레이블은 `american_bulldog`가 됩니다.

<codeblock id="02_02">
첫 번째와 두 번째 파라미터의 역할이 무엇인지 생각해 보세요!
</codeblock>

약간은 복잡한 방식으로 해결책을 찾으셨을지도 모르겠습니다. 그리고 사실은 마지막 언더바(`_`)와 이어지는 숫자 앞까지는 어떤 문자열이라도 올 수 있습니다. 지금처럼 문자열을 자르고 붙이는 방법으로도 문제를 해결할 수는 있지만, 주어진 문자열에서 특정 패턴을 따르는 부분만을 추출하는 더 나은 방법을 우리는 알고 있습니다. 바로 [정규표현식(Regular Expression)](https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C_%ED%91%9C%ED%98%84%EC%8B%9D)을 사용하는 것이죠.

위 파일명에서 레이블 추출을 하기위한 정규표현식은 `r'^(.*)_\d+.jpg'` 정도로 작성할 수 있습니다. 정규표현식이 꽤 어렵게 느껴지는 분은 관련 내용을 먼저 읽은 다음 돌아오시기 바랍니다. 간단히 설명하자면 `\d`는 단일 숫자를 의미하며, `\d+`는 숫자 여러개가 올 수 있다는것을 의미합니다. 그리고 `.*`는 어떤 문자라도 여러개 등장할 수 있다는것을 뜻하며, `^`은 문자열의 시작을 의미합니다. 따라서 `문자여러개_숫자여러개.jpg`와 같은 패턴을 표현하고 있죠. 이 때 괄호(`()`)는 해당 괄호속의 부분 문자열을 추출하겠다는 의미를 가집니다. 따라서 `문자여러개_숫자여러개.jpg` 패턴을 만족하는 문자열이라면, 여기서 `문자여러개` 부분만 추출하겠다는 것입니다. 

`from_name_func` 메서드용 함수를 만들고, 주어진 파일명에 정규 표현식을 직접 적용해도 무방합니다. 다만 약간의 귀찮은 과정을 간소화 하고자 fastai에서는 `from_name_re` 라는 또 다른 (팩터리)메서드를 제공합니다. 이름에서 알 수 있듯이 `re` 정규표현식을 레이블 추출에 쓰겠다는것이죠. 즉 `from_name_func` 메서드의 세 번째 파라미터로 함수가 지정되었다면, `from_name_re` 메서드의 세 번째 파라미터로는 정규표현식이 지정되어야 합니다.

아래 코드를 완성해보세요. `from_name_re` 메서드에 정규표현식을 사용하여 파일명에서 동물의 **품종** 정보를 추출해 레이블로 할당합니다.

<codeblock id="02_03">
정규 표현식을 입력해 주세요! 본문을 참고하기 바랍니다!
</codeblock>

</exercise>

<exercise id="3" title="팬더스 DataFrame으로 입력 데이터를 준비하기">

때로는 디렉터리의 구조, 파이명 규칙에 별 다른 의미를 부여하지 않는 경우도 많이 접할 수 있습니다. 이 때는 보통 `csv` 파일이나 팬더스의 `DataFrame`(데이터프레임) 형식으로 각 파일에 매핑된 레이블을 표 형식으로 관리하곤 하죠. 

이를위해 [`ImageDataLoaders`](https://docs.fast.ai/vision.data.html#ImageDataLoaders) 클래스는 [`from_df`](https://docs.fast.ai/vision.data.html#ImageDataLoaders.from_df)와 [`from_csv`](https://docs.fast.ai/vision.data.html#ImageDataLoaders.from_csv) (팩터리)메서드를 제공합니다. 여기서는 그 중 `from_df` 메서드를 알아볼텐데, 사용시 아래 나열된 몇 가지 파라미터만 익숙해지면 됩니다. 
- **첫 번째 파라미터**: 정보가 담긴 팬더스 `DataFrame` 인스턴스를 지정합니다.
- **path**: 입력 데이터인 파일이 담긴 기본 디렉터리를 지정합니다. 만약 이미지 파일명에 전체 디렉터리 경로도 포함되어 있다면 설정할 필요가 없지만(기본값 `.`), 경로를 제외한 파일명만 존재한다면 이 파라미터를 추가적으로 설정해야합니다.
- **folder**: **path**가 베이스 경로를 지정한다면, 이 파라미터는 베이스 경로내 특정 폴더를 지정하는 데 사용됩니다. 
- **valid_pct**: 전체 데이터 중 검증용 데이터셋의 비율을 지정합니다. 기본 값은 `0.2`로 20%를 뜻하며, 이 파라미터는 `ImageDataLoaders`의 모든 (팩터리)메서드에서 지원합니다.
- **fn_col**: 입력될 이미지 파일명(경로까지도 포함되었을 수 있음)이 기록된 열/컬럼 이름을 지정합니다. 참고로 **fn**은 filename(파일명)을 의미합니다.
- **label_col**: 입력될 레이블이 기록된 열/컬럼 이름을 지정합니다.
- **label_delim**: 때로는 [멀티 레이블 분류 문제](https://en.wikipedia.org/wiki/Multi-label_classification)를 풀어야 할 때가 있습니다. 즉 각 이미지가 하나 이상의 범주에 속하는 경우죠. 이 경우 레이블 열에는 하나 이상의 레이블이 포함될 수 있으며, 각 레이블을 구분하는 구분자가 있을 수 있습니다. 가령 `동물 강아지` 라고 적혔다면, `공백 문자`를 기준으로 두 레이블을 분리해냅니다. 이 파라미터는 이 구분자를 지정하며, 지정하지 않는경우 **단일 레이블 분류 문제**로 다룹니다.
- **valid_col**: 때로는 검증용으로 사용되어야 할 데이터를 별도로 명시하는 경우가 있습니다. 즉 검증을 위해 세심하게 디자인된 데이터 목록이 존재하는 것이죠. 이 파라미터에 검증용으로 사용되어야 할 데이터를 표시해둔 열/컬럼 이름을 지정하면, 여기서 읽어들인 데이터를 검증용 데이터로 활용하게 됩니다.

아래 코드를 실행해 보세요. 그러면 `PASCAL_2007` 데이터셋에 포함된 `csv` 파일을 팬더스 `DataFrame`으로 읽어들인 후 포함된 일부 데이터를 확인할 수 있습니다. 이 `DataFrame` 정보를 기반으로 이어지는 코드를 완성해 보세요.

<codeblock id="02_04">
문제가 아닙니다! DataFrame 확인을 위해 코드를 실행해 보세요!
</codeblock>

위 `DataFrame`을 확인했다면 해당 정보로 입력 데이터를, `ImageDataLoaders.from_df` 메서드로 구성해보세요.

<codeblock id="02_05">
</codeblock>

</exercise>

<exercise id="4" title="준비된 입력 데이터로 모델 학습시키기">

앞서 언급한대로 fastai는 이미지 분류 모델을 만드는 가장 간단한 방법으로 `ImageDataLoaders` 객체와 `cnn_learner` 함수를 제공합니다. 머신러닝으로 문제를 해결하려면 **1. 데이터** 와 **2. 모델 및 모델을 학습시키는 기법** 이 필요하며, 이 둘이 각각에 대응되는 역할을 합니다(참고로 `ImageDataLoaders`를 사용하지 않고 입력 데이터를 준비하는 방법은 추후 다룹니다).

지금까지 1~3 섹션을 통해 입력 데이터를 준비해봤으므로, 이제 준비된 입력 데이터를 **학습**한 모델을 만들어보죠. [`cnn_learner`](https://docs.fast.ai/vision.learner.html#cnn_learner) 함수는 **컨볼루션(합성곱) 신경망** 구조에 기반한 모델이 주어진 입력 데이터를 학습하는 빠른 수단을 제공합니다. 빠른 수단을 제공하는것 이면에, 이 함수에 입력 가능한 수 많은 파라미터에는 이미지넷과 유사한 데이터에서 잘 작동한다고 판단되는 기본 값을 배정해 두었습니다. 이들에 대한것은 차차 알아보도록 해요. 다만 반드시 입력되어야 하는 첫 번째와 두 번째 파라미터를 살펴보겠습니다.

- **첫 번째 파라미터**: `DataLoaders` 유형의 객체(인스턴스)를 지정합니다. 앞서 1~3 섹션에서 팩터리 메서드로 만들었던 `dls` 라는 이름의 변수에 담긴것이 바로 `DataLoaders` 유형의 객체입니다. 
- **두 번째 파라미터**: 첫 번째 파라미터로 주어진 데이터를 학습할 모델의 기본 구조를 선택합니다. 선택 가능한 모델의 종류는 [`models`](https://github.com/fastai/fastai/blob/master/fastai/vision/models/tvm.py) 모듈에 정의되어 있습니다. 

사실 모델들은 순수 PyTorch로 정의된것입니다. 다만 기존의 **사전-학습된** 모델을 나만의 문제에 적용하려면, 사전-학습된 문제에만 특화된 부분은 잘라내고, 나만의 문제에 알맞은 **부분-구조**를 덧대어야만 합니다. `cnn_learner` 함수는 이 작업을 자동으로 수행해주는 데, 그 이면에는 각 모델마다 fastai에서 매핑해둔 메타데이터가 있기 때문에 가능한 것입니다. 따라서 다른 PyTorch 모델을 사용해도 무방하지만, `cnn_learner`를 그대로 사용하고 싶다면 별도의 메타데이터도 같이 작성해야만하죠(`cnn_learner` 없이 사용하는 방법은 추후 다룹니다).

이렇게 두 파라미터를 제공해 `cnn_learner` 함수를 호출하면 [`Learner`](https://docs.fast.ai/learner.html#Learner) 유형의 객체가 만들어집니다. 그리고 `Learner` 객체는 지정된 모델로 지정된 데이터셋을 학습하는 다양한 수단을 제공하죠. 특히 [`fine_tune(에포크횟수)`](https://docs.fast.ai/callback.schedule.html#Learner.fine_tune) 메서드는 지정된 에포크 횟수만큼 fastai가 생각한 가장 최적의 방식으로 학습을 자동 수행하는 기능을 합니다. 

한번 해보죠. 아래 코드를 완성해서 첫 번째 섹션에서 만든 `DataLoaders`를 `models.resnet18` 모델로, 1 에포크만큼만 학습시켜보세요
* _실습 환경이 CPU 인스턴스기 때문에 데이터셋 자체도 매우 작게(약 20개), 배치 크기도 매우 작게, 모델도 가장 작은것(resnet18), 에포크 횟수도 가능한 한 작게 유지합니다_
* _학습된 결과에는 신경쓰지 마세요. API 사용법을 익히는게 목적이며, 제대로된 결과를 확인하려면 [Colab](https://research.google.com/colaboratory/) 또는 [Sagemaker Studio Lab](https://studiolab.sagemaker.aws/)과 같은 환경에서 완전한 데이터셋(`URLs.PETS`)을 사용해야만 합니다._

<codeblock id="02_06">
</codeblock>

</exercise>

<exercise id="5" title="cnn_learner 함수의 다른 파라미터 둘러보기" type="slides">

<slides source="chapter2_05">
</slides>

</exercise>

<exercise id="6" title="정확도 평가지표 추가해서 학습시켜보기">

앞서 살펴본 `cnn_learner` 함수의 파라미터 내용으로부터 간단한 문제를 하나 풀어보죠. 다음 중 모니터링 하고자하는 **평가 지표**를 지정하는 파라미터와, 모델의 머리 구조의 **선형 층의 특징 수**를 제어하는 파라미터는 무엇인가요?

<choice>
<opt text="metrics; lin_ftrs" correct="true"></opt>
<opt text="metrics; first_bn"></opt>
<opt text="metrics; lin_first"></opt>
<opt text="metrics; ps"></opt>
<opt text="cbs; lin_ftrs"></opt>
<opt text="cbs; first_bn"></opt>
<opt text="cbs; lin_first"></opt>
<opt text="cbs; ps"></opt>
</choice>

그러면 `metrics` 파라미터에 **정확도** 평가지표를 추가한 채 다시 한번 모델을 학습시켜보겠습니다. 정확도 평가지표는 `accuracy`로 지정될 수 있습니다. 아래의 코드를 완성해 보세요. 그리고 `Learner` 객체의 `recorder` 속성(`Recorder` 객체)의 `plot_loss()` 메서드로, 학습 과정에서 측정된 손실의 추이를 그래프로 확인할 수 있다는 사실도 확인해 보세요.

<codeblock id="02_07">
metrics 파라미터에 accuracy를 등록해 보세요!
</codeblock>

이번에는 직접 **정확도** 평가지표를 계산하는 함수를 만들어보겠습니다. `my_accuracy` 라는 함수를 만들텐데요, 모델의 예측(`input`)과 레이블(`target`) 두 파라미터를 수용합니다. 

이 둘의 자료형은 fastai에서 정의해둔 `TensorBase`와 `TensorCategory`지만, fastai에서 별도로 정의해둔 텐서 자료형은 모두 PyTorch의 텐서를 확장해 만든것입니다. 따라서 PyTorch의 표준 연산이 모두 사용 가능하므로, 단순히 PyTorch의 텐서로 생각하고 사용하여도 무방합니다. 

참고로 `input` 텐서의 모양은 **배치 크기 x 범주의 개수** 이며, `target` 텐서의 모양은 **배치 크기**의 벡터 입니다. 즉 `input` 텐서는 한 배치를 구성하는 각 입력에 대한 각 범주 별 확률 값을 예측한 것이며, `target` 텐서는 한 배치를 구성하는 각 입력에 대한 실제 레이블을 정수로 표현한 것입니다. 이를 통해 계산된 정확도를 반환해 보세요. 
- 감이 잘 안온다면 [공식 구현체](https://github.com/fastai/fastai/blob/351f4b9314e2ea23684fb2e19235ee5c5ef8cbfd/fastai/metrics.py#L97)를 참고해 보세요(거의 그대로 복사했습니다). 
- 그리고 `my_accuracy` 함수내에서 각 파라미터의 유형, 크기, 실제 들어있는 값 등을 직접 `print`로 출력해보며 감을 익혀보기 바랍니다. 

<codeblock id="02_08">
argmax와 mean 메서드를 활용해 보세요!
</codeblock>

</exercise>

<exercise id="7" title="모델의 형상 파악하기">

만들어진 `Learner` 객체는 몇 가지 유용한 메서드를 제공합니다. 그 중 `summary()`에 대해 살펴보죠. 

`Learner`의 [`summary()`]((https://github.com/fastai/fastai/blob/351f4b9314e2ea23684fb2e19235ee5c5ef8cbfd/fastai/callback/hook.py#L207)) 메서드는 `Learner`에 주입된 모델의 형상을 파악하는 데 유용한 기능을 제공합니다. 이미 Keras의 모델 요약 기능을 써본적이 있다면, 매우 친숙한 느낌의 출력물을 확인할 수 있습니다. 여기에 추가적으로, fastai는 `Learner` 객체에 추가되어 있는 콜백 목록과, 현재 학습 가능한 파라미터 그룹까지도 한 눈에 확인할 수 있도록 만들어두었습니다. 

아래의 코드를 완성하여 `summary()` 메서드의 출력 결과를 확인해 보세요. `Model frozen up to parameter group #2` 라는 문구가 출력 결과에 포함되어 있을겁니다. 이 말의 의미는 전체 파라미터 그룹(리스트) 중 두 번째(`#2`) 까지가 동결되어, 학습을 진행하더라도 가중치 갱신이 이루어지지 않음을 의미합니다. 

<codeblock id="02_09">
</codeblock>

그러면 이번에는 모든 파라미터의 동결을 해제한 뒤 다시 `summary()` 메서드의 출력 결과를 살펴보겠습니다. 아래 코드를 완성해 보세요. 동결 해제에는 `unfreeze()`, 동결에는 `freeze()` 메서드가 사용됩니다. 출력 결과가 `Model unfrozen` 라고 바뀌었고, `Trainable` 열이 모두 `True`로 바뀌어 **학습(가중치 갱신)이 가능한** 상태임을 알려줍니다. 

<codeblock id="02_10">
</codeblock>

그렇다면 어떤 근거로, 모델의 특정 그룹이 동결될 것인지가 결정될 수 있을까요? 그 대답은 [`cnn_learner` 함수의 구현체](https://github.com/fastai/fastai/blob/6e44b354f4d12bdfa2c9530f38f851c54a05764d/fastai/vision/learner.py#L162)를 살펴보면 알 수 있습니다. 다소 내용이 복잡할 수는 있으므로 동결에 대한 부분만 설명해보죠. 내부적으로 아래와 같은 순서로 일이 처리됩니다.
1. CNN(컨볼루션 신경망) 모델을 만들기위해 [`create_cnn_model`](https://github.com/fastai/fastai/blob/6e44b354f4d12bdfa2c9530f38f851c54a05764d/fastai/vision/learner.py#L139) 함수를 호출합니다.
2. `create_cnn_model` 함수 내부에서는 1️⃣기존 모델의 머리와 몸통을 분리해낼 메타데이터를 가져오고, 2️⃣ 메타데이터에 기록된 인덱스를 기준으로 몸통만 따로 분리한 다음, 3️⃣ 새로운 머리(나의 작업에 특화된)를 이어 붙여 모델을 완성합니다. 즉 (원래모델의 몸통, 새로붙인 머리) 튜플이 만들어지는 것이죠. 그리고 실제로 인덱싱 `[0]`, `[1]` 을 통해 각 부분에 접근하는것도 가능합니다. 
3. 그리고 마지막으로 `Learner` 객체에 `splitter` 파라미터를 넘겨줍니다. 이 파라미터로는 파라미터 리스트를 반환하는 함수가 지정되어야 합니다. 그리고 이 함수가 반환하는 리스트의 요소 중 마지막을 기준으로 **동결**시킬 그룹이 나뉘어집니다. 한편 이 파라미터 그룹은 **동결** 목적에만 사용되는것은 아닙니다. fastai의 차별적 학습률 적용 기법에서도 활용되는 부분으로, 여기에 명시된 그룹별로 서로 다른 학습률을 배정해 학습을 진행시킬 수도 있습니다 ([ResNet 계열의 `splitter` 함수의 구현체](https://github.com/fastai/fastai/blob/6e44b354f4d12bdfa2c9530f38f851c54a05764d/fastai/vision/learner.py#L105)).

그러면 이 사실을 한번 눈으로 확인해보죠. 우선 메타 데이터의 생김새를 확인합니다. 참고로 메타 데이터는 `model_meta[모델명]`으로 가져올 수 있습니다(여러분이 직접 모델을 만든다면 별도로 메타 데이터를 등록해 줘야합니다).

<codeblock id="02_11">
</codeblock>

보다시피 머리와 몸통을 분리할 지점(인덱스)인 `cut`, `splitter`로 사용될 함수인 `_resnet_split`이 메타 데이터로 등록된 것을 확인할 수 있습니다. 그러면 이번에는 `Learner` 객체에 할당된 모델의 어느 부분이 `splitter`에 영향을 받는지 확인해보죠. 

<codeblock id="02_12">
</codeblock>

출력 결과와 [ResNet 계열의 `splitter` 함수의 구현체](https://github.com/fastai/fastai/blob/6e44b354f4d12bdfa2c9530f38f851c54a05764d/fastai/vision/learner.py#L105)를 비교해보죠. **몸통**의 길이는 8인데, `splitter`의 반환 값 중 처음 두 개에 `0~5`, `6~8` 번째의 부분-몸통이 할당되어 있습니다. 또한 반환 값의 마지막애는 **머리**가 통째로 할당되었습니다. 즉 **동결**시 마지막 **머리**를 제외한 나머지가 **동결** 된다는 의미이며, 차별적 학습률이 적용될 때는 **몸통의 두 부분**과 **머리**, 즉 세 부분에 대해 서로다른 학습률을 할당하겠다고 해석될 수 있습니다. 

</exercise>

<exercise id="8" title="학습 루프의 형상 파악하기">

일부 딥러닝 프레임워크의 경우, 제공되는 상위 API만으로는 학습 루프를 입맛대로 조정하기 어려운 경우가 있습니다. 이 경우 학습 루프를 직접 작성하고, 각 단계별 원하는 지점에 추가적인 연산 작업을 삽입할 필요가 있습니다. fastai 라이브러리는 완전한 관리형 학습 루프를 제공합니다. 그리고 학습 루프를 구성하는 각 단계별 추가적인 작업을 적용해야 한다면, 원하는 시점에 대한 로직만을 담은 **콜백(Callback)**을 작성해서 `Learner`에 심어주는 방식을 채택하고 있습니다. 또한 한 가지 특이한 점은 모델, 데이터, 피드 포워드의 예측 결과, 손실 등의 거의 모든 정보에 접근할 수 있을 뿐만아니라, 거의 모든 정보를 **on the fly** 방식으로 수정할 수 있습니다.

- 이에 대한 한 가지 예로는 `Mixup`과 같은 기법이 있습니다. 데이터 배치를 구성하기 전 믹스업 기법을 적용하는 방식으로 구현되어 있죠. 또한 **Gradient Clipping**, **멀티 GPU**로 분산시키는 방법 등 플레인 학습 루프의 행동을 벗어나는 거의 모든 행동은 **콜백**으로 구현되어 있습니다. 

다만 **콜백**을 많이 추가하다보면, 각 콜백이 학습 루프의 어느 시점에 호출되는지 헷갈리는 경우가 발생할 수 있습니다. 이를 위해 `Learner` 객체는 [`show_training_loop()`](https://github.com/fastai/fastai/blob/f05e1160f8a688359f7875feb24e80906f1fceb5/fastai/learner.py#L281) 메서드를 제공합니다. 이 메서드를 통해 학습 루프의 각 시점에 어떤 콜백이 심어져 있는지를 한 눈에 파악할 수 있습니다. 가령 아래와 같은 이벤트에 접근할 수 있죠.

- **begin_fit**: 전체 학습이 진행되기 전의 이벤트를 낚아챕니다.
- **begin_epoch**: 각 에포크 시작, 그러나 학습이 진행되기 전의 이벤트를 낚아챕니다. 각 에포크에서 무언가를 초기화 할 때 유용합니다.
- **begin_train**: 각 에포크별 학습용 데이터에 대한 학습이 시작되기 직전의 이벤트를 낚아챕니다.
- **begin_batch**: 각 에포크에 주입되는 각 배치가 모델에 주입되기 전의 이벤트를 낚아챕니다.
- **after_pred**: 각 에포크에 주입되는 각 배치가 모델에 주입된 후, 예측이 계산된 직후의 이벤트를 낚아챕니다.
- **after_loss**: 각 에포크에 주입되는 각 배치가 모델에 주입된 후, 손실이 계산된 직후의 이벤트를 낚아챕니다.
- **after_backward**: 각 에포크에 주입되는 각 배치가 모델에 주입된 후, 역전파가 계산된 직후의 이벤트를 낚아챕니다 (파라미터가 갱신되기 직전입니다).
- **after_step**: 각 에포크에 주입되는 각 배치가 모델에 주입된 후, 역전파가 계산된 직후의 이벤트를 낚아챕니다 (파라미터가 갱신된 직후, 그래디언트가 0으로 초기화 되기 직전입니다).
- **after_batch**: 각 에포크에 주입되는 각 배치에 대한 모든 작업이 완료된 직후의 이벤트를 낚아챕니다.
- **after_train**: 각 에포크 학습이 끝난 직후의 이벤트를 낚아챕니다. 
- **begin_validate**: 각 에포크별 검증용 데이터에 대한 계산이 수행되기 직전의 이벤트를 낚아챕니다.
- **after_validate**: 각 에포크별 검증용 데이터에 대한 계산이 수행된 직후의 이벤트를 낚아챕니다.
- **after_epoch**: 각 에포크 끝의 이벤트를 낚아챕니다.
- **after_fit**: 전체 학습이 종료된 후의 이벤트를 낚아챕니다.

또한 각 이벤트 발생시, 어떤 조건에 의해 각 이벤트를 그대로 건너뛰기 위한 예외를 제공합니다. 필요시 예외를 발생시키면되죠. 그리고 혹시 예외가 발생했다면, 발생한 예외에 따른 추가적인 액션을 취하기 위한 별도의 이벤트도 제공합니다. 다음과 같은 목록을 제공하며, 보다시피 이름을 보는 것만으로도 어떤일을 하는지 알 수 있습니다. `CancelBatchException`, `CancelTrainException`, `CancelValidException`, `CancelEpochException`, `CancelFitException`, `after_cancel_batch`, `after_cancel_train`, `after_cancel_valid`, `after_cancel_epoch`, `after_cancel_fit`.

_옵티마이저의 작동은 콜백을 통해 이루어지지 않습니다. 옵티마이저는 제네릭 `Optimizer`를 상속 받아, 경우에 따라 옵티마이저용 별도의 **콜백**을 추가해 구현될 수 있습니다. 참고로 제네릭 `Optimizer`는 계산된 경사도를 0으로 만드는 과정, 그리고 삽입된 **콜백**을 순차적으로 처리하기 위한 루틴(루프)를 포함합니다. 그리고 모델을 구성하는 파라미터, 파라미터 그룹, 각 콜백이 반환할 수 있는 상태(`state`) 딕셔너리, 하이퍼파라미터에 접근할 수 있습니다._

<codeblock id="02_13">
</codeblock>

</exercise>